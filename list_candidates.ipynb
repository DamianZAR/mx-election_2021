{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposals of Mexican candidates 2021\n",
    "\n",
    "Author: Damián Zamora Rivas\n",
    "<br>This script is part of my article wrote in my blog in Medium: **https://damzar.medium.com/**\n",
    "\n",
    "If you want to read how was used and an analysis of the results of this script, the article link is:\n",
    "* **English version**: To be wrote\n",
    "* **Spanish version**: To be wrote\n",
    "\n",
    "All script was written in spanish, because all data where come from is in spanish. So I did not see a need to manipulate them in english. However, comments are in english.\n",
    "\n",
    "From the page https://candidaturas.ine.mx/ a spreadsheet was downloaded on June 3th. You can find it as I downloaded in my kaggle profile: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One\n",
    "### Downloading and creating of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request, urllib.parse, urllib.error  #Useful libraries to get acces to a web page\n",
    "import PyPDF2                                      #useful library to manipulate pdf files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two functions are difined. \n",
    "* The first one is to download the resume of each candidate from the web.\n",
    "* The second one is to extract specific text from each resume downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to download a pdf file\n",
    "#Input variable: pdf url\n",
    "#Output variable: pdf file (called pdffile) saved in the same directory of this script\n",
    "#NOTE: If this function is working in a loop, don't open the file pdffile.pdf\n",
    "\n",
    "def download_pdf(url):\n",
    "    \n",
    "    pdf = urllib.request.urlopen(url).read()\n",
    "    \n",
    "    pdffile = open('pdffile.pdf', 'wb')\n",
    "    pdffile.write(pdf)\n",
    "    pdffile.close()\n",
    "    \n",
    "    file = 'pdffile.pdf'\n",
    "    \n",
    "    return file\n",
    "\n",
    "#|||-------------------------------------------------------------------------------------------------------------------|||#\n",
    "\n",
    "#Extraction function to get data from each candidate's resume in pdf, which is generated by download_pdf function \n",
    "#Input variable: temporal file in pdf format (resume)\n",
    "#Output variable: List of 7 data: Age, Sex, Academic Degree, Why I want a public office?, Main Proposals \n",
    "# Gender Matter Proposal, Facebook profile\n",
    "def extraccion(file):\n",
    "    \n",
    "    #Reading and extraction of the text from the resume in pdf\n",
    "    read_pdf = PyPDF2.PdfFileReader(file)\n",
    "    page = read_pdf.getPage(0)\n",
    "    page_content = page.extractText()\n",
    "    lista_cv = list()\n",
    "    \n",
    "    #1. Age\n",
    "\n",
    "    i = 0\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if page_content[i-1] == 'h' and page_content[i] == 't' and page_content[i+1] == 't':\n",
    "            for q in range(100):\n",
    "                i = i + 1\n",
    "                if (page_content[i-1] == 'R' and page_content[i] == 'e' and page_content[i+1] == 'd'\n",
    "                and page_content[i+2] == 'e' and page_content[i+3] == 's' and page_content[i+4] == ' '):\n",
    "                    aux = i\n",
    "                    break\n",
    "            for p in range(aux, 500):\n",
    "                i = i + 1\n",
    "                if (page_content[i] == '0' or page_content[i] == '1' or page_content[i] == '2' \n",
    "                 or page_content[i] == '3' or page_content[i] == '4' or page_content[i] == '5' \n",
    "                 or page_content[i] == '6' or page_content[i] == '7' or page_content[i] == '8' \n",
    "                 or page_content[i] == '9'):\n",
    "                    edad = page_content[i] + page_content[i+1]\n",
    "                    break\n",
    "            break\n",
    "        \n",
    "        elif (letter == '0' or letter == '1' or letter == '2' or letter == '3' or letter == '4'\n",
    "           or letter == '5' or letter == '6' or letter == '7' or letter == '8' or letter == '9'):\n",
    "            edad = page_content[i-1] + page_content[i]\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    lista_cv.append(int(edad))\n",
    "\n",
    "    #2. Sex\n",
    "\n",
    "    i = 0\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if letter == 'ñ':\n",
    "            if page_content[i+2] == 'M':\n",
    "                sexo = 'Mujer'\n",
    "                break\n",
    "            else:\n",
    "                sexo = 'Hombre'\n",
    "                break\n",
    "\n",
    "    lista_cv.append(sexo)\n",
    "    \n",
    "    #3. Academic Degree\n",
    "\n",
    "    i = 0\n",
    "    estudios = list()\n",
    "\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if i == len(page_content):\n",
    "            page_aux = read_pdf.getPage(1)\n",
    "            page_content_aux = page_aux.extractText()\n",
    "        \n",
    "            l = 0\n",
    "            for let in page_content_aux:\n",
    "                l = l + 1\n",
    "                if page_content_aux[l] == 's' and page_content_aux[l+1] == 'G' and page_content_aux[l+2] == 'r':\n",
    "                    l = l + 25\n",
    "                    for q in range(int(len(page_content_aux)/2)):\n",
    "                        l = l + 1\n",
    "                        estudios.append(page_content_aux[l])\n",
    "                        if page_content_aux[l+1] == 'E' and page_content_aux[l+2] == 's' and page_content_aux[l+3] == 't':\n",
    "                            break\n",
    "                    break    \n",
    "        \n",
    "        if i < len(page_content):\n",
    "            if page_content[i] == 's' and page_content[i+1] == 'G' and page_content[i+2] == 'r':\n",
    "                i = i + 25\n",
    "                for q in range(int(len(page_content)/2)):\n",
    "                    i = i + 1\n",
    "                    estudios.append(page_content[i])\n",
    "                    if page_content[i+1] == 'E' and page_content[i+2] == 's' and page_content[i+3] == 't':\n",
    "                        break\n",
    "                break\n",
    "\n",
    "    educacion = \"\".join(estudios)\n",
    "    lista_cv.append(educacion)\n",
    "\n",
    "    #4. Why I want a public office?\n",
    "\n",
    "    i = 0\n",
    "    quiero_cargo = list()\n",
    "\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if letter == '¿':\n",
    "            i = i + 38\n",
    "            for q in range(int(len(page_content)/2)):\n",
    "                i = i + 1\n",
    "                quiero_cargo.append(page_content[i])\n",
    "                if page_content[i+1] == 'D' and page_content[i+2] == 'o' and page_content[i+3] == 's':\n",
    "                    break\n",
    "            break\n",
    "                \n",
    "    pquiero = \"\".join(quiero_cargo)\n",
    "    lista_cv.append(pquiero)\n",
    "    \n",
    "    #5. Main Proposals\n",
    "\n",
    "    i = 0\n",
    "    propuesta = list()\n",
    "\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if page_content[i] == 'D' and page_content[i+1] == 'o' and page_content[i+2] == 's':\n",
    "            i = i + 43\n",
    "            for q in range(int(len(page_content)/2)):\n",
    "                i = i + 1\n",
    "                propuesta.append(page_content[i])\n",
    "                if (page_content[i+16] == 't' and page_content[i+17] == 'e' and page_content[i+18] == 'r' \n",
    "                    and page_content[i+19] == 'i' and page_content[i+20] == 'a' and page_content[i+21] == ' '\n",
    "                    and page_content[i+22] == 'd' and page_content[i+23] == 'e' and page_content[i+24] == ' '\n",
    "                    and page_content[i+25] == 'g' and page_content[i+26] == 'é' and page_content[i+27] == 'n'):\n",
    "                    break\n",
    "            break\n",
    "        \n",
    "    prop = \"\".join(propuesta)\n",
    "    lista_cv.append(prop)\n",
    "\n",
    "    #6. Gender Matter Proposal\n",
    "\n",
    "    i = 0\n",
    "    propuesta_gen = list()\n",
    "\n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if (page_content[i] == 't' and page_content[i+1] == 'e' and page_content[i+2] == 'r' \n",
    "            and page_content[i+3] == 'i' and page_content[i+4] == 'a' and page_content[i+5] == ' ' \n",
    "            and page_content[i+6] == 'd' and page_content[i+7] == 'e' and page_content[i+8] == ' ' \n",
    "            and page_content[i+9] == 'g' and page_content[i+10] == 'é' and page_content[i+11] == 'n'):\n",
    "            i = i + 83\n",
    "            for q in range(int(len(page_content)/2)):\n",
    "                i = i + 1\n",
    "                propuesta_gen.append(page_content[i])\n",
    "                if (page_content[i+1] == 'T' and page_content[i+2] == 'r' and page_content[i+3] == 'a' \n",
    "                    and page_content[i+4] == 'y' and page_content[i+5] == 'e' and page_content[i+6] == 'c'):\n",
    "                    break\n",
    "            break\n",
    "\n",
    "    materia_gen = \"\".join(propuesta_gen)\n",
    "    lista_cv.append(materia_gen)\n",
    "    \n",
    "    #7. Facebook profile\n",
    "    i = 0\n",
    "    redfb = list()\n",
    "    \n",
    "    for letter in page_content:\n",
    "        i = i + 1\n",
    "        if page_content[i-1] == 'h' and page_content[i] == 't' and page_content[i+1] == 't':\n",
    "            for q in range(int(len(page_content)/2)):\n",
    "                i = i + 1\n",
    "                redfb.append(page_content[i-2])\n",
    "                if (page_content[i-1] == 'R' and page_content[i] == 'e' and page_content[i+1] == 'd'\n",
    "                and page_content[i+2] == 'e' and page_content[i+3] == 's' and page_content[i+4] == ' '):\n",
    "                    break\n",
    "            fb = \"\".join(redfb)\n",
    "            lista_cv.append(fb)\n",
    "            break\n",
    "        else:\n",
    "            fb = 'Sin registro'\n",
    "            lista_cv.append(fb)\n",
    "            break\n",
    "    \n",
    "    return lista_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the dictionary to homogenize all politic parties\n",
    "\n",
    "partidict = {'CANDIDATURA INDEPENDIENTE':'Independiente', 'FUERZA POR MÉXICO':'Fuerza por México',\n",
    "             'JUNTOS HACEMOS HISTORIA': 'PT, Partido Verde, Morena', 'MORENA':'Morena', \n",
    "             'MOVIMIENTO CIUDADANO':'Movimiento Ciudadano', 'PARTIDO ACCIÓN NACIONAL': 'PAN', \n",
    "            'PARTIDO DE LA REVOLUCIÓN DEMOCRÁTICA':'PRD', 'PARTIDO DEL TRABAJO':'PT', 'PARTIDO ENCUENTRO SOLIDARIO':'PES',\n",
    "            'PARTIDO REVOLUCIONARIO INSTITUCIONAL':'PRI', 'PARTIDO VERDE ECOLOGISTA DE MÉXICO':'Partido Verde',\n",
    "            'REDES SOCIALES PROGRESISTAS':'RSP', 'VA POR MEXICO':'PAN, PRI, PRD'}\n",
    "\n",
    "#Creation of the dataframe where will be the extracted data of all candidates\n",
    "df_candidatos = pd.DataFrame(columns = ('Estado','Distrito','Actor Político','Partido','Nombre','Propiedad',\n",
    "                                       'Edad','Sexo','Grado Académico','¿Por qué quiero un cargo público?',\n",
    "                                       'Principales Propuestas','Propuesta en materia de género','Facebook'))\n",
    "\n",
    "encabezado = ['Estado','Distrito','Actor Político','Partido','Nombre','Propiedad',\n",
    "                                       'Edad','Sexo','Grado Académico','¿Por qué quiero un cargo público?',\n",
    "                                       'Principales Propuestas','Propuesta en materia de género','Facebook']\n",
    "\n",
    "#Here is the spreadsheet downloaded from the official page of candidates\n",
    "df_dmr = pd.read_excel('candidates_mx2021.xlsx')  \n",
    "\n",
    "#Pre-cleaning: searching and replacement for NaN registers\n",
    "i = 0 \n",
    "for Bool in df_dmr['CurriculumV Suplente'].isnull():\n",
    "    i = i + 1\n",
    "    if Bool == True:\n",
    "        df_dmr['CurriculumV Suplente'][i-1] = 0\n",
    "i = 0\n",
    "for Bool in df_dmr['CurriculumV Propietario'].isnull():\n",
    "    i = i + 1\n",
    "    if Bool == True:\n",
    "        df_dmr['CurriculumV Suplente'][i-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web Scraping\n",
    "\n",
    "#Variables to use in loops\n",
    "len_dmr = len(df_dmr)\n",
    "len_ren = len(df_dmr.iloc[0])\n",
    "a = 0\n",
    "b = 0\n",
    "falta = len(df_dmr) - 30\n",
    "\n",
    "for i in range(len_dmr):\n",
    "    \n",
    "    a = a + 1\n",
    "    par = 2*a - 2\n",
    "    b = b + 1\n",
    "    impar = 2*b - 1\n",
    "\n",
    "    #Candidates\n",
    "    \n",
    "    lista_can = list()\n",
    "    lista_sup = list()\n",
    "            \n",
    "    for f in range(3):\n",
    "        lista_can.append(df_dmr.iloc[i,f])\n",
    "        lista_sup.append(df_dmr.iloc[i,f])\n",
    "    \n",
    "    for j in range(len_ren):\n",
    "        \n",
    "        for k in partidict.keys():\n",
    "            if df_dmr.iloc[i,j] == k:\n",
    "                lista_can.append(partidict[k])\n",
    "                lista_sup.append(partidict[k])\n",
    "                lista_can.append(df_dmr.iloc[i,j+1])\n",
    "                lista_sup.append(df_dmr.iloc[i,j+3])\n",
    "                lista_can.append('Candidato')\n",
    "                lista_sup.append('Suplente')\n",
    "                break\n",
    "    \n",
    "    if df_dmr.loc[i,'CurriculumV Propietario'] == 0:\n",
    "        for col in range(7):\n",
    "            lista_can.append('Sin registro')\n",
    "    else:\n",
    "        aux = list(str(df_dmr.loc[i,'CurriculumV Propietario']))\n",
    "        l = 0\n",
    "        for let in aux:\n",
    "            l = l + 1\n",
    "            if let == 'Ñ':\n",
    "                aux[l-1] = '%C3%91'\n",
    "        url = ''.join(aux)                \n",
    "        \n",
    "        try:\n",
    "            archivo = download_pdf(url)\n",
    "        except:\n",
    "            print('Error de conexión')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            lista_cv = extraccion(archivo)\n",
    "            for l in lista_cv:\n",
    "                lista_can.append(l)\n",
    "        except:\n",
    "            for l in range(7):\n",
    "                lista_can.append('Sin Registro')\n",
    "    \n",
    "    df_candidatos.loc[par,encabezado] = lista_can\n",
    "    \n",
    "    #Substitutes (they also are candidates, but secondary)\n",
    "    \n",
    "    if df_dmr.loc[i,'CurriculumV Suplente'] == 0:\n",
    "        for col in range(7):\n",
    "            lista_sup.append('Sin registro')\n",
    "    else:\n",
    "        aux = list(str(df_dmr.loc[i,'CurriculumV Suplente']))\n",
    "        l = 0\n",
    "        for let in aux:\n",
    "            l = l + 1\n",
    "            if let == 'Ñ':\n",
    "                aux[l-1] = '%C3%91'\n",
    "        url = ''.join(aux)\n",
    "        \n",
    "        try:\n",
    "            archivo = download_pdf(url)\n",
    "        except:\n",
    "            print('Error de conexión')\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            lista_cv = extraccion(archivo)\n",
    "            for l in lista_cv:\n",
    "                lista_sup.append(l)\n",
    "        except:\n",
    "            for l in range(7):\n",
    "                lista_sup.append('Sin Registro')\n",
    "    \n",
    "    df_candidatos.loc[impar,encabezado] = lista_sup\n",
    "    \n",
    "    #I added this part because the data extraction took a long time, \n",
    "    # and I wanted to get an idea of how the process was going.\n",
    "    falta = falta - 1\n",
    "    if falta%30 == 10:\n",
    "        print('Faltan aproximadamente', falta, 'candidatos por procesar.')\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataframe created is saved as a cvs file, which also is in the kaggle link:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidatos.to_csv('data_candidates_mx2021.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two\n",
    "### Natural Language Processing\n",
    "\n",
    "To all program be easier to manipulate, this part starts with the reading of the csv file created past part, as it were another program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataf = pd.read_csv('data_candidates_mx2021.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
